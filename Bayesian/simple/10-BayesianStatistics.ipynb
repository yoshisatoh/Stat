{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics in Python\n",
    "In this chapter we will introduce how to basic Bayesian computations using Python.\n",
    "\n",
    "## Applying Bayes' theorem: A simple example\n",
    "TBD: MOVE TO MULTIPLE TESTING EXAMPLE SO WE CAN USE BINOMIAL LIKELIHOOD\n",
    "A person has a cough and flu-like symptoms, and gets a PCR test for COVID-19, which comes back postiive.  What is the likelihood that they actually have COVID-19, as opposed to a regular cold or flu?  We can use Bayes' theorem to compute this.  Let's say that the local rate of symptomatic individuals who actually are infected with COVID-19 is 7.4% (as [reported](https://twitter.com/Bob_Wachter/status/1281792549309386752/photo/1) on July 10, 2020 for San Francisco); thus, our prior probability that someone with symptoms actually has COVID-19 is .074.  The RT-PCR test used to identify COVID-19 RNA is highly specific (that is, it very rarelly reports the presence of the virus when it is not present); for our example, we will say that the specificity is 99%.  Its sensitivity is not known, but probably is no higher than 90%.  \n",
    "First let's look at the probability of disease given a single positive test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "\n",
    "sensitivity = 0.90\n",
    "specificity = 0.99\n",
    "prior = 0.074\n",
    "likelihood = sensitivity  # p(test|disease present) \n",
    "marginal_likelihood = sensitivity * prior + (1 - specificity) * (1 - prior)\n",
    "posterior = (likelihood * prior) / marginal_likelihood\n",
    "posterior\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high specificity of the test, along with the relatively high base rate of the disease, means that most people who test positive actually have the disease. \n",
    "Now let's plot the posterior as a function of the prior.  Let's first create a function to compute the posterior, and then apply this with a range of values for the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_posterior(prior, sensitivity, specificity):\n",
    "    likelihood = sensitivity  # p(test|disease present) \n",
    "    marginal_likelihood = sensitivity * prior + (1 - specificity) * (1 - prior)\n",
    "    posterior = (likelihood * prior) / marginal_likelihood\n",
    "    return(posterior)\n",
    "\n",
    "\n",
    "prior_values = np.arange(0.001, 0.5, 0.001)\n",
    "posterior_values = compute_posterior(prior_values, sensitivity, specificity)\n",
    "\n",
    "plt.plot(prior_values, posterior_values)\n",
    "plt.xlabel('prior')\n",
    "_ = plt.ylabel('posterior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure highlights a very important general point about diagnostic testing: Even when the test has high specificity, if a condition is rare then most positive test results will be false positives.\n",
    "\n",
    "## Estimating posterior distributions \n",
    "In this example we will look at how to estimate entire posterior distributions.  \n",
    "We will implement the [drug testing example](https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html#estimating-posterior-distributions) from the book.  In that example, we administered a drug to 100 people, and found that 64 of them responded positively to the drug. What we want to estimate is the probability distribution for the proportion of responders, given the data. For simplicity we started with a uniform prior; that is, all proprtions of responding are equally likely to begin with. In addition, we will use a discrete probability distribution; that is, we will estimate the posterior probabiilty for each particular proportion of responders, in steps of 0.01.  This greatly simplifies the math and still retains the main idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+\n",
    "num_responders = 64\n",
    "num_tested = 100\n",
    "\n",
    "bayes_df = pd.DataFrame({'proportion': np.arange(0.0, 1.01, 0.01)})\n",
    "\n",
    "# compute the binomial likelihood of the observed data for each\n",
    "# possible value of proportion\n",
    "bayes_df['likelihood'] = scipy.stats.binom.pmf(num_responders,\n",
    "                                               num_tested,\n",
    "                                               bayes_df['proportion'])\n",
    "# The prior is equal for all possible values\n",
    "bayes_df['prior'] = 1 / bayes_df.shape[0]\n",
    "\n",
    "# compute the marginal likelihood by adding up the likelihood of each possible proportion times its prior probability.\n",
    "\n",
    "marginal_likelihood = (bayes_df['likelihood'] * bayes_df['prior']).sum()\n",
    "\n",
    "bayes_df['posterior'] = (bayes_df['likelihood'] * bayes_df['prior']) / marginal_likelihood\n",
    "\n",
    "# plot the likelihood, prior, and posterior\n",
    "\n",
    "plt.plot(bayes_df['proportion'], bayes_df['likelihood'], label='likelihood')\n",
    "plt.plot(bayes_df['proportion'], bayes_df['prior'], label='prior')\n",
    "plt.plot(bayes_df['proportion'], bayes_df['posterior'],\n",
    "         'k--', label='posterior')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the posterior and likelihood are virtually identical, which is due to the fact that the prior is uniform across all possible values.  Now let's look at a case where the prior is not uniform. Let's say that we now run a larger study of 1000 people with the same treatment, and we find that 312 of the 1000 individuals respond to the treatment.  In this case, we can use the posterior from the earlier study of 100 people as the prior for our new study.  This is what we sometimes refer to as *Bayesian updating*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+\n",
    "num_responders = 312\n",
    "num_tested = 1000\n",
    "\n",
    "# copy the posterior from the previous analysis and rename it as the prior\n",
    "\n",
    "study2_df = bayes_df[['proportion', 'posterior']].rename(columns={'posterior': 'prior'})\n",
    "\n",
    "# compute the binomial likelihood of the observed data for each\n",
    "# possible value of proportion\n",
    "\n",
    "study2_df['likelihood'] = scipy.stats.binom.pmf(num_responders,\n",
    "                                               num_tested,\n",
    "                                               study2_df['proportion'])\n",
    "\n",
    "# compute the marginal likelihood by adding up the likelihood of each possible proportion times its prior probability.\n",
    "\n",
    "marginal_likelihood = (study2_df['likelihood'] * study2_df['prior']).sum()\n",
    "\n",
    "study2_df['posterior'] = (study2_df['likelihood'] * study2_df['prior']) / marginal_likelihood\n",
    "\n",
    "# plot the likelihood, prior, and posterior\n",
    "\n",
    "plt.plot(study2_df['proportion'], study2_df['likelihood'], label='likelihood')\n",
    "plt.plot(study2_df['proportion'], study2_df['prior'], label='prior')\n",
    "plt.plot(study2_df['proportion'], study2_df['posterior'],\n",
    "         'k--', label='posterior')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see two important things. First, we see that the prior is substantially wider than the likelihood, which occurs because there is much more data going into the likelihood (1000 data points) compared to the prior (100 data points), and more data reduces our uncertainty.  Second, we see that the posterior is much closer to the value observed for the second study than for the first, which occurs for the same reason --- we put greater weight on the estimate that is more precise due to a larger sample. \n",
    "\n",
    "## Bayes factors\n",
    "There are no convenient off-the-shelf tools for estimating Bayes factors using Python, so we will use the `rpy2` package to access the `BayesFactor` library in R.  Let's compute a Bayes factor for a T-test comparing the amount of reported alcohol computing between smokers versus non-smokers.  First, let's set up the NHANES data and collect a sample of 150 smokers and 150 nonsmokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#+\n",
    "from nhanes.load import load_NHANES_data\n",
    "nhanes_data = load_NHANES_data()\n",
    "adult_nhanes_data = nhanes_data.query('AgeInYearsAtScreening > 17')\n",
    "rseed = 1\n",
    "\n",
    "# clean up smoking variables\n",
    "adult_nhanes_data.loc[adult_nhanes_data['SmokedAtLeast100CigarettesInLife'] == 0, 'DoYouNowSmokeCigarettes'] = 'Not at all'\n",
    "adult_nhanes_data.loc[:, 'SmokeNow'] = adult_nhanes_data['DoYouNowSmokeCigarettes'] != 'Not at all'\n",
    "\n",
    "# Create average alcohol consumption variable between the two dietary recalls\n",
    "adult_nhanes_data.loc[:, 'AvgAlcohol'] = adult_nhanes_data[['AlcoholGm_DR1TOT', 'AlcoholGm_DR2TOT']].mean(1)\n",
    "adult_nhanes_data = adult_nhanes_data.dropna(subset=['AvgAlcohol'])\n",
    "\n",
    "sample_size_per_group = 150\n",
    "\n",
    "nonsmoker_sample = adult_nhanes_data.query('SmokeNow == False').sample(sample_size_per_group, random_state=rseed)[['SmokeNow', 'AvgAlcohol']]\n",
    "smoker_sample = adult_nhanes_data.query('SmokeNow == True').sample(sample_size_per_group, random_state=rseed)[['SmokeNow', 'AvgAlcohol']]\n",
    "\n",
    "full_sample = pd.concat((nonsmoker_sample, smoker_sample))\n",
    "full_sample.loc[:, 'SmokeNow'] = full_sample['SmokeNow'].astype('int')\n",
    "full_sample.groupby('SmokeNow').mean()\n",
    "#-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use functions from R to perform a standard t-test as well as compute a Bayes Factor for this comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#+\n",
    "\n",
    "# import the necessary functions from rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "pandas2ri.activate()\n",
    "\n",
    "# import the BayesFactor package\n",
    "BayesFactor = importr('BayesFactor')\n",
    "\n",
    "# import the data frames into the R workspace\n",
    "robjects.globalenv[\"smoker_sample\"] = smoker_sample\n",
    "robjects.globalenv[\"nonsmoker_sample\"] = nonsmoker_sample\n",
    "\n",
    "# perform the standard t-test\n",
    "ttest_output = r('print(t.test(smoker_sample$AvgAlcohol, nonsmoker_sample$AvgAlcohol, alternative=\"greater\"))')\n",
    "\n",
    "# compute the Bayes factor\n",
    "r('bf = ttestBF(y=nonsmoker_sample$AvgAlcohol, x=smoker_sample$AvgAlcohol, nullInterval = c(0, Inf))')\n",
    "r('print(bf[1]/bf[2])')\n",
    "\n",
    "#-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the difference between these groups is significant, and the Bayes factor suggests fairly strong evidence for a difference."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
